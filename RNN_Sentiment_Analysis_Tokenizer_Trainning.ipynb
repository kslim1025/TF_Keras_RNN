{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_Sentiment_Analysis_Tokenizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyORV9GcX9VC5pEIVzcqHMCx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kslim1025/TF_Keras_RNN/blob/master/RNN_Sentiment_Analysis_Tokenizer_Trainning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X33UMrVR1Nj",
        "outputId": "ae723f0e-752d-4005-d4cc-297c02850387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# MNIST 문자열 분석으로 유명한 데이터셋이 패션에 관한 데이터 세트를 만듬 그게 FashionMINIST 데이터셋이다.\n",
        "# 데이터 이미지가 0에서 255까지 값을 가지는 28x28이미지라는 것을 확인가능\n",
        "# 정답이 되는 라벨을 확인하기 위해 print를 붙여서  확인\n",
        "# 외부 데이터를 이용한 정제과정\n",
        "# ctrl+enter를 사용한 런타임가능\n",
        "# !nvidia-smi : 어떤 GPU를 사용하는지 확인가능한 명령어 \n",
        "#\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# 넘파이는 수학과 과학 연산에 특화된 파이썬 모듈로 딥러닝에서도 유용하게 사용된다.\n",
        "\n",
        "import numpy as np;\n",
        "import tensorflow as tf;\n",
        "import pandas as pd;\n",
        "import matplotlib.pyplot as plt;\n",
        "import math;\n",
        "################################################################################\n",
        "!nvidia-smi\n",
        "       \n",
        "#+-----------------------------------------------------------------------------+\n",
        "#| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
        "#|-------------------------------+----------------------+----------------------+\n",
        "#| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "#| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "#|                               |                      |               MIG M. |\n",
        "#|===============================+======================+======================|\n",
        "#|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
        "#| N/A   51C    P0    35W / 250W |   1581MiB / 16280MiB |      0%      Default |\n",
        "#|                               |                      |                 ERR! |\n",
        "#+-------------------------------+----------------------+----------------------+\n",
        "#                                                                               \n",
        "#+-----------------------------------------------------------------------------+\n",
        "#| Processes:                                                                  |\n",
        "#|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
        "#|        ID   ID                                                   Usage      |\n",
        "#|=============================================================================|\n",
        "#|  No running processes found                                                 |\n",
        "#+-----------------------------------------------------------------------------+\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# 긍정, 부정 감성 분석\n",
        "# 감성분석은 입력된 자연어 안의 주관적의견, 감정 등을 찾아낸다.\n",
        "# 이 가운데 극성(polarity) 감성 분석은 문장의 궁정/부정이나 긍정/중립/부정으로 분류합니다.\n",
        "# 영화 리뷰이나 음식점 리뷰는 데이터의 양이 많고 별점을 함꼐 달기 때문에 긍정/중립/부정 라벨링이 쉬워서 극성 감성 분석에 쉽게 적용할 수 있습니다.\n",
        "\n",
        "# 1. 데이터 세트를 불러오기\n",
        "path_to_train_file = tf.keras.utils.get_file('train.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt')\n",
        "path_to_train_file = tf.keras.utils.get_file('test.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt')\n",
        "\n",
        "# 2. 데이터 메모리 불러오기\n",
        "train_text = open(path_to_train_file, 'rb').read().decode(encoding='utf-8')\n",
        "test_text = open(path_to_train_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "#텍스트가 총 몇자인지 확인\n",
        "print('텍스트의 길이 : {} characters'.format(len(train_text)))\n",
        "print('텍스트의 길이 : {} characters'.format(len(test_text)))\n",
        "print()\n",
        "\n",
        "#처음 300자를 확인해봅니다.\n",
        "print(train_text[:300])\n",
        "\n",
        "train_Y =  np.array([[int(row.split('\\t')[2])] for row in train_text.split('\\n')[1:] if row.count('\\t') > 0 ])\n",
        "test_Y =  np.array([[int(row.split('\\t')[2])] for row in test_text.split('\\n')[1:] if row.count('\\t') > 0 ])\n",
        "\n",
        "print(train_Y.shape, test_Y.shape)\n",
        "print(train_Y[:5])\n",
        "\n",
        "import re \n",
        "# from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
        "\n",
        "def clean_str(string):\n",
        "  string = re.sub(r\"[^가-힣A-Za-z0-9(),!?'\\']\",\" \",string)\n",
        "  string = re.sub(r\"\\'s\", \"\\'s\", string)\n",
        "  string = re.sub(r\"\\'ve\",\"\\'ve\",string)\n",
        "  string = re.sub(r\"n\\'t\", \"n\\'t\",string)\n",
        "  string = re.sub(r\"\\'re\",\"\\'re\",string)\n",
        "  string = re.sub(r\"\\'d\",\"\\'d\",string)\n",
        "  string = re.sub(r\"\\'ll\",\"\\'ll\",string)\n",
        "  string = re.sub(r\",\",\",\",string)\n",
        "  string = re.sub(r\"!\",\" ! \",string)\n",
        "  string = re.sub(r\"\\(\", \" \\( \",string)\n",
        "  string = re.sub(r\"\\)\", \" \\) \",string)\n",
        "  string = re.sub(r\"\\?\", \" \\? \",string)\n",
        "  string = re.sub(r\"\\?\", \" \\? \",string)\n",
        "  string = re.sub(r\"\\s{2,}\",\" \",string)\n",
        "  string = re.sub(r\"\\s{2,}\",\"\\'\",string)\n",
        "  string = re.sub(r\"\\'\",\"\",string)\n",
        "  \n",
        "  return string.lower()\n",
        "\n",
        "train_text_X = [row.split('\\t')[1] for row in train_text.split('\\n')[1:] if row.count('\\t') > 0]\n",
        "train_text_X = [clean_str(sentence) for sentence in train_text_X]\n",
        "\n",
        "# 문장을 띄어쓰기 단위로 단어 분리\n",
        "sentences = [sentence.split(' ') for sentence in train_text_X]\n",
        "for i in range(5):\n",
        "  print(sentences[i])\n",
        "\n",
        "sentence_len = [len(sentence) for  sentence in sentences]\n",
        "sentence_len.sort()\n",
        "plt.plot(sentence_len)\n",
        "plt.show()\n",
        "\n",
        "# 25 단어 이하인 문장수는 142.587개로 전체의 95%정도로 확인\n",
        "print(sum([int(1<=25) for l in sentence_len]))\n",
        "\n",
        "#단어 정제 및 문장 길이를 줄이는 작업\n",
        "sentences_new = []\n",
        "for sentence in sentences:\n",
        "  sentences_new.append([word[:5] for word in sentence][:25])\n",
        "\n",
        "sentences = sentences_new\n",
        "\n",
        "for i in range(5):\n",
        "  print(sentences[i])\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=200000)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "train_X = tokenizer.texts_to_sequences(sentences)\n",
        "train_X = pad_sequences(train_X, padding='post')\n",
        "\n",
        "print(train_X[:5])\n",
        "\n",
        "#Tokenizer의 동작확인\n",
        "# tokenizer.index_word[19999]과 tokenizer.index_word[20000]번째 있는 단어를 확인해본뒤 이단어들로 구성된 문장을  Tokenizer안에 넣어줌\n",
        "print(tokenizer.index_word[19999])\n",
        "print(tokenizer.index_word[20000])\n",
        "\n",
        "temp = tokenizer.texts_to_sequences(['#$#$','경우는','잊혀질','연기가'])\n",
        "\n",
        "print(temp)\n",
        "temp = pad_sequences(temp, padding='post')\n",
        "print(temp)\n",
        "\n",
        "#감성 분석을 위한 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "                            tf.keras.layers.Embedding(20000, 300, input_length=25),\n",
        "                            tf.keras.layers.LSTM(units=50),\n",
        "                            tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#감성 분석 모델 학습\n",
        "#history = model.fit(train_X, train_Y, epochs=5, batch_size=128, validation_split=0.2)\n",
        "history = model.fit(train_X, train_Y, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "#감성 분석 모델의 학습 결과 확인\n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.histpry['val_loss'],'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], 'g-', label='accuracy')\n",
        "plt.plot(history.histpry['val_accuracy'],'k--', label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0.7, 1)\n",
        "plt.legend()\n",
        "\n",
        "test_text_X = [row.split('\\t')[1] for row in test_text.split('\\n')[1:] if row.count('\\t') > 0]\n",
        "test_text_X = [clean_str(sentence) for sentence in test_text_X]\n",
        "sentences =[sentence.split(' ') for sentence in test_text_X]\n",
        "sentences = sentences_new\n",
        "\n",
        "test_X = tokenizer.texts_to_sequences(sentence)\n",
        "test_X = pad_sequences(test_X, padding='post')\n",
        "\n",
        "model.evaluate(test_X, test_Y, verbose=0)\n",
        "\n",
        "test_sentence = '딥러닝으로 임베디드 레이어 테스트'\n",
        "test_sentence = test_sentence.split(' ')\n",
        "test_sentences = []\n",
        "now_sentence = []\n",
        "for word in test_sentence:\n",
        "  now_sentence.append(word)\n",
        "  test_sentences.append(now_sentence[:])\n",
        "\n",
        "  test_X_1 = tokenizer.texts_to_sequences(test_sentences)\n",
        "  test_X_1 = pad_sequences(test_X_1, padding='post', maxlen=25)\n",
        "  prediction = model.predict(test_X_1)\n",
        "  for idx, sentence in enmerate(test_senteces):\n",
        "    print(sentence)\n",
        "    print(prediction[idx])\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n",
            "텍스트의 길이 : 2318260 characters\n",
            "텍스트의 길이 : 2318260 characters\n",
            "\n",
            "id\tdocument\tlabel\n",
            "6270596\t굳 ㅋ\t1\n",
            "9274899\tGDNTOPCLASSINTHECLUB\t0\n",
            "8544678\t뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\t0\n",
            "6825595\t지루하지는 않은데 완전 막장임... 돈주고 보기에는....\t0\n",
            "6723715\t3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\t0\n",
            "7898805\t음악이 주가 된, 최고의 음악영화\t1\n",
            "6315043\t진정한 쓰레기\t0\n",
            "6097171\t마치 미국애니에서 튀어나온듯한 창의력없는 로봇디자인부터\n",
            "(50000, 1) (50000, 1)\n",
            "[[1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n",
            "['굳', '']\n",
            "['gdntopclassintheclub']\n",
            "['뭐야', '이', '평점들은', '나쁘진', '않지만', '10점', '짜리는', '더더욱', '아니잖아']\n",
            "['지루하지는', '않은데', '완전', '막장임', '돈주고', '보기에는', '']\n",
            "['3d만', '아니었어도', '별', '다섯', '개', '줬을텐데', '왜', '3d로', '나와서', '제', '심기를', '불편하게', '하죠', '\\\\', '\\\\?', '\\\\', '\\\\?', '']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "['굳', '']\n",
            "['gdnto']\n",
            "['뭐야', '이', '평점들은', '나쁘진', '않지만', '10점', '짜리는', '더더욱', '아니잖아']\n",
            "['지루하지는', '않은데', '완전', '막장임', '돈주고', '보기에는', '']\n",
            "['3d만', '아니었어도', '별', '다섯', '개', '줬을텐데', '왜', '3d로', '나와서', '제', '심기를', '불편하게', '하죠', '\\\\', '\\\\?', '\\\\', '\\\\?', '']\n",
            "[[  464     1     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [30038     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  299     9 17373  5680  1133    80 17374  6579  1487     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [ 9430  1928    37 17375   581  1621     1     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [17376  7707   111  7708   289 17377    11  2246   379   565 30039  5681\n",
            "   9431     4     5     4     5     1     0     0     0     0     0     0\n",
            "      0]]\n",
            "별로,\n",
            "놀랠\n",
            "[[], [6750], [22501], [98]]\n",
            "[[    0]\n",
            " [ 6750]\n",
            " [22501]\n",
            " [   98]]\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 25, 300)           6000000   \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 50)                70200     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 6,070,302\n",
            "Trainable params: 6,070,302\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e0c801f58f2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;31m#감성 분석 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;31m#history = model.fit(train_X, train_Y, epochs=5, batch_size=128, validation_split=0.2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;31m#감성 분석 모델의 학습 결과 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  indices[113,5] = 78141 is not in [0, 20000)\n\t [[node sequential_4/embedding_4/embedding_lookup (defined at <ipython-input-19-e0c801f58f2a>:156) ]] [Op:__inference_train_function_10268]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_4/embedding_4/embedding_lookup:\n sequential_4/embedding_4/embedding_lookup/9126 (defined at /usr/lib/python3.6/contextlib.py:81)\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    }
  ]
}