{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageNet_cv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/FNipPr4ywnSqjiW9j01H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kslim1025/TF_Keras_RNN/blob/master/ImageNet_cv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X33UMrVR1Nj",
        "outputId": "eb136ab9-df0d-4978-8632-4caeb83226e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        }
      },
      "source": [
        "# MNIST 문자열 분석으로 유명한 데이터셋이 패션에 관한 데이터 세트를 만듬 그게 FashionMINIST 데이터셋이다.\n",
        "# 데이터 이미지가 0에서 255까지 값을 가지는 28x28이미지라는 것을 확인가능\n",
        "# 정답이 되는 라벨을 확인하기 위해 print를 붙여서  확인\n",
        "# 외부 데이터를 이용한 정제과정\n",
        "# ctrl+enter를 사용한 런타임가능\n",
        "# !nvidia-smi : 어떤 GPU를 사용하는지 확인가능한 명령어 \n",
        "#\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# 넘파이는 수학과 과학 연산에 특화된 파이썬 모듈로 딥러닝에서도 유용하게 사용된다.\n",
        "\n",
        "import numpy as np;\n",
        "import tensorflow as tf;\n",
        "import pandas as pd;\n",
        "import matplotlib.pyplot as plt;\n",
        "import math;\n",
        "import re;\n",
        "################################################################################\n",
        "!nvidia-smi\n",
        "       \n",
        "#+-----------------------------------------------------------------------------+\n",
        "#| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
        "#|-------------------------------+----------------------+----------------------+\n",
        "#| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "#| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "#|                               |                      |               MIG M. |\n",
        "#|===============================+======================+======================|\n",
        "#|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
        "#| N/A   51C    P0    35W / 250W |   1581MiB / 16280MiB |      0%      Default |\n",
        "#|                               |                      |                 ERR! |\n",
        "#+-------------------------------+----------------------+----------------------+\n",
        "#                                                                               \n",
        "#+-----------------------------------------------------------------------------+\n",
        "#| Processes:                                                                  |\n",
        "#|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
        "#|        ID   ID                                                   Usage      |\n",
        "#|=============================================================================|\n",
        "#|  No running processes found                                                 |\n",
        "#+-----------------------------------------------------------------------------+\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# 텐서플로 2.0을 이용한 턴서플로 허브 불러오는 방법\n",
        "\n",
        "#1. 텐서플로 허브에서 사전 훈련된 MobileNet 모델 불러오기\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "mobile_net_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2\"\n",
        "model = tf.keras.Sequential([\n",
        "  hub.KerasLayer(handle = mobile_net_url, input_shape=(224,224,3), trainable=False)\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# MobileNet 이란?\n",
        "\n",
        "#MobileNet은 계산 부담이 큰 컨볼루션 신경망을 연산 성능이 제한적인 모바일 환경에서도 작동 가능하도록 네트워크 구조를 경량화한것입니다.\n",
        "#MobileNet 버전2는 1을 개선했고 파라미터 수도 더 줄어들었습니다.\n",
        "\n",
        "#MobileNet은 ImageNet에 존재하는 1,000 종류의 이미지를 분류할 수 있으며, 이 가운데 어떤것에도 속하지 않는다고 판단될 때는 background에 해당 하는 인덱스 0을 반환합니다. 이미지의 분류는 수량(cock)과 암탉(hen)을 분류할 정도로 상세하고 화장지(toilet tissue)같은 사물도 포함되어있다.\n",
        "\n",
        "#MobileNet의 성능을 평가하기 위해 이미지를 학습시켰을 때 얼마나 적합한 라벨로 분류하는지 알아보겠습니다.\n",
        "#ImageNet의 데이터 중 일부만 모아놓은 ImageNetV2를 사용하겠습니다. ImageNetV2는 아마존 매커니컬 터크를 이용해 다수의 참가자에게서 클래스 예측값을 받아서 선별한 데이터입니다. 여기서는 각클래스에서 가장 많은 선택을 받은 이미지 10장씩 모아놓은 10,000장의 이미지가 포함된 TopImages 데이터를 사용하겠습니다.\n",
        "\n",
        "# imageNetV2-TopImages 불러오기\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "content_data_url = '/content/sample_data'\n",
        "data_root_orig = tf.keras.utils.get_file('imagenetV2', 'https://s3-us-west-2.amazonaws.com/imagenetv2public/imagenetv2-topimages.tar.gz', cache_dir=content_data_url, extract=True)\n",
        "data_root= pathlib.Path(content_data_url + '/datasets/imagenetv2-topimages')\n",
        "print(data_root)\n",
        "\n",
        "# 디렉터리 출력\n",
        "for idx, item in enumerate(data_root.iterdir()):\n",
        "#for idx, item in enumerate('C:/Users/kslim/Desktop/datasets/imagenetv2-topimages'):\n",
        "  print(item)\n",
        "  if idx == 9:\n",
        "    break\n",
        "\n",
        "# ImageNet 라벨 텍스트 불러오기\n",
        "\n",
        "label_file = tf.keras.utils.get_file('label', 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
        "\n",
        "label_text = None\n",
        "with open(label_file, 'r') as f:\n",
        "  label_text = f.read().split('\\n')[:-1]\n",
        "\n",
        "print(len(label_text))\n",
        "print(label_text[:10])\n",
        "print(label_text[-10:])\n",
        "\n",
        "# 이미지 확인\n",
        "\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "all_image_paths = list(data_root.glob('*/*'))\n",
        "all_image_paths = [str(path) for path in all_image_paths]\n",
        "\n",
        "#이미지를 랜덤하게 섞습니다\n",
        "random.shuffle(all_image_paths)\n",
        "\n",
        "image_count = len(all_image_paths)\n",
        "print('image_count', image_count)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "for c in range(9):\n",
        "  image_path = random.choice(all_image_paths)\n",
        "  plt.subplot(3,3,c+1)\n",
        "  plt.imshow(plt.imread(image_path))\n",
        "  idx = int(image_path.split('/')[-2]) + 1\n",
        "  plt.title(str(idx) + ', ' + label_text[idx])\n",
        "  plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "#MobileNet분류의 성능 확인\n",
        "import cv2\n",
        "\n",
        "top_1 = 0\n",
        "top_5 = 0\n",
        "for image_path in all_image_paths:\n",
        "  img = cv2.imread(image_path)\n",
        "  img = cv2.resize(img, dsize = (224, 224))\n",
        "  img = img /255.0\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  top_5_predict = model.predict(img)[0].argsort()[::-1][:5]\n",
        "  idx = int(image_path.split('/')[-2])+1\n",
        "  if idx in top_5_predict:\n",
        "    top_5 +=1\n",
        "    if top_5_predict[0] ==dix:\n",
        "      top_1 += 1\n",
        "\n",
        "print('Top-5 correctness: ', top_5 / len(all_image_paths) * 100, '%')\n",
        "print('Top-1 correctness: ', top_1 / len(all_image_paths) * 100, '%')\n",
        "\n",
        "a = np.array([99, 32, 5, 64])\n",
        "arg = np.argsort(a)\n",
        "\n",
        "print(arg)\n",
        "print(np.sort(a))\n",
        "print(a[arg])\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "\n",
        "def softmax(x):\n",
        "  e_x = np.exp(x -np.max(x))\n",
        "  return e_x / e_x.sum(axis=0)\n",
        "\n",
        "for c in range(3):\n",
        "  image_path = random.choice(all_image_paths)\n",
        "\n",
        "  #이미지 표시\n",
        "  plt.subplot(3,2,c*2+1)\n",
        "  plt.imshow(plt.imread(image_path))\n",
        "  idx = int(image_path.split('/')[-2] + 1)\n",
        "  plt.title(str(idx) + ', ' + label_text[idx])\n",
        "  plt.axis('off')\n",
        "\n",
        "  #예측값 표시\n",
        "  plt.subplot(3,2,c*2+2)\n",
        "  img = cv2.imread(image_path)\n",
        "  img = cv2.resize(img, dsize=(224, 224))\n",
        "  img = img /255.0\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "\n",
        "  #MobileNet을 이용한 예측\n",
        "  ogits = model.predict(img)[0]\n",
        "  prediction = softmax(logits)\n",
        "\n",
        "  #가장 높은 확률의 예측값 5개를 뽑음\n",
        "  top_5_predict = rediction.argsor()[::sort][:5]\n",
        "  labels = [label_text[index] for index in top_5_predict]\n",
        "  color = ['gray'] * 5\n",
        "  if idx in top_5_predict:\n",
        "    color[top_5_predict.tolist().index(idx)] = 'green'\n",
        "  color = color[::-1]\n",
        "  plt.barh(range(5), prediction[top_5_predict][::-1] *100, color=color)\n",
        "  plt.yticks(range(5), label[::-1])\n",
        "\n",
        "#전이학습 (Transfer Learning)\n",
        "import os\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = 'user_id' #독자의 캐글 ID\n",
        "os.environ['KAGGLE_KEY'] = 'user_api_token' #독자의 캐글 API Token\n",
        "!kaggle competitions download -c dog-breed-identification\n",
        "\n",
        "!unzip train.zip\n",
        "!unzip labels.csv.zip\n",
        "\n",
        "import pandas as pd\n",
        "label_text = pd.read_csv('label_csv')\n",
        "print(label_text.head())\n",
        "\n",
        "label_text.info()\n",
        "\n",
        "label_text['bread'].nunique()\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "for c in range(9):\n",
        "  image_id = label_text.loc[c, 'id']\n",
        "  plt.subplot(3, 3, c+1)\n",
        "  plt.imshow(plt.imread('/content/train/' + image_id + '.jpg'))\n",
        "  plt.title(str(c) + ', ' + label_text.loc[c, 'breed'])\n",
        "  plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_14 (KerasLayer)  (None, 1001)              3540265   \n",
            "=================================================================\n",
            "Total params: 3,540,265\n",
            "Trainable params: 0\n",
            "Non-trainable params: 3,540,265\n",
            "_________________________________________________________________\n",
            "/content/sample_data/datasets/imagenetv2-topimages\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-b17164901d9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# 디렉터리 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;31m#for idx, item in enumerate('C:/Users/kslim/Desktop/datasets/imagenetv2-topimages'):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/pathlib.py\u001b[0m in \u001b[0;36miterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                 \u001b[0;31m# Yielding a path object for these makes little sense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/pathlib.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(pathobj, *args)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sample_data/datasets/imagenetv2-topimages'"
          ]
        }
      ]
    }
  ]
}